{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "821c87aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-1.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting langchain-core<2.0.0,>=1.0.0 (from langchain)\n",
      "  Downloading langchain_core-1.0.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting langgraph<1.1.0,>=1.0.0 (from langchain)\n",
      "  Downloading langgraph-1.0.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading pydantic-2.12.3-py3-none-any.whl.metadata (87 kB)\n",
      "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Downloading langsmith-0.4.37-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /home/ubuntu/.venv/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (25.0)\n",
      "Collecting pyyaml<7.0.0,>=5.3.0 (from langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (2.4 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /home/ubuntu/.venv/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (4.15.0)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading langgraph_checkpoint-3.0.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading langgraph_prebuilt-1.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting xxhash>=3.5.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading xxhash-3.6.0-cp310-cp310-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (13 kB)\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading ormsgpack-1.11.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (1.2 kB)\n",
      "Collecting httpx>=0.25.2 (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson>=3.10.1 (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading orjson-3.11.3-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting requests>=2.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Downloading zstandard-0.25.0-cp310-cp310-manylinux2014_aarch64.manylinux_2_17_aarch64.whl.metadata (3.3 kB)\n",
      "Collecting anyio (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting certifi (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.4 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.41.4-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (37 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ubuntu/.venv/lib/python3.10/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (1.3.0)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Downloading langchain-1.0.1-py3-none-any.whl (106 kB)\n",
      "Downloading langchain_core-1.0.0-py3-none-any.whl (467 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langgraph-1.0.1-py3-none-any.whl (155 kB)\n",
      "Downloading langgraph_checkpoint-3.0.0-py3-none-any.whl (46 kB)\n",
      "Downloading langgraph_prebuilt-1.0.1-py3-none-any.whl (28 kB)\n",
      "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
      "Downloading langsmith-0.4.37-py3-none-any.whl (396 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading pydantic-2.12.3-py3-none-any.whl (462 kB)\n",
      "Downloading pydantic_core-2.41.4-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyyaml-6.0.3-cp310-cp310-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (740 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m740.6/740.6 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading orjson-3.11.3-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (123 kB)\n",
      "Downloading ormsgpack-1.11.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (195 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (148 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading xxhash-3.6.0-cp310-cp310-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (212 kB)\n",
      "Downloading zstandard-0.25.0-cp310-cp310-manylinux2014_aarch64.manylinux_2_17_aarch64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: zstandard, xxhash, urllib3, typing-inspection, tenacity, sniffio, pyyaml, pydantic-core, ormsgpack, orjson, jsonpointer, idna, h11, charset_normalizer, certifi, annotated-types, requests, pydantic, jsonpatch, httpcore, anyio, requests-toolbelt, httpx, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langgraph-prebuilt, langgraph, langchain\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30/30\u001b[0m [langchain]30\u001b[0m [langgraph]core]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 anyio-4.11.0 certifi-2025.10.5 charset_normalizer-3.4.4 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.11 jsonpatch-1.33 jsonpointer-3.0.0 langchain-1.0.1 langchain-core-1.0.0 langgraph-1.0.1 langgraph-checkpoint-3.0.0 langgraph-prebuilt-1.0.1 langgraph-sdk-0.2.9 langsmith-0.4.37 orjson-3.11.3 ormsgpack-1.11.0 pydantic-2.12.3 pydantic-core-2.41.4 pyyaml-6.0.3 requests-2.32.5 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.1.2 typing-inspection-0.4.2 urllib3-2.5.0 xxhash-3.6.0 zstandard-0.25.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8952999",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6233b36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\"/home/ubuntu/project/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fcc84f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93b0f9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b67f8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key = API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c67cd4",
   "metadata": {},
   "source": [
    "### 랭체인 사용 Open ai 호출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "609bd528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTHONIOENCODING\"] = \"utf-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69206a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U \"openai>=1.51.0\" \"httpx>=0.27.0\" \"langchain>=0.3.0\" \"langchain-openai>=0.2.0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f1968b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "하늘이 파란 이유는 대기 중의 산란 과정 때문입니다. 태양 빛은 여러 색의 빛으로 구성되어 있으며, 이 색들은 각각 다른 파장을 가지고 있습니다. 파장이 짧은 파란색 빛은 대기 중의 분자와 입자에 의해 다른 색보다 더 많이 산란됩니다. \n",
      "\n",
      "해가 높이 떠 있을 때, 태양 빛이 대기를 통과하면서 파란색 빛이 다양한 방향으로 퍼져 나가고, 그 결과 우리는 하늘이 파랗게 보이게 됩니다. 이 현상을 '레이리 산란'이라고 부릅니다. 반대로, 해가 지거나 떠오를 때, 태양 빛은 더 많은 대기를 통과하게 되므로 빨강, 주황색과 같은 긴 파장의 색이 더 많이 산란되어 하늘이 붉거나 주황색으로 보이기도 합니다.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# .env 로드\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "assert api_key, \"OPENAI_API_KEY 가 없습니다 (.env 확인)\"\n",
    "assert all(ord(c) < 128 for c in api_key), \"API 키에 비-ASCII 문자가 섞였습니다\"\n",
    "\n",
    "# LangChain 클라이언트: 조직/프로젝트/프록시/UA를 깨끗하게\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    openai_api_key=api_key,\n",
    "    # organization=None, project=None  # 필요한 경우 명시 가능\n",
    "    default_headers={\"User-Agent\": \"langchain-openai\"},  # ASCII만\n",
    ")\n",
    "\n",
    "resp = llm.invoke(\"하늘은 왜 파란가요?\")\n",
    "print(resp.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "974d8dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain은 언어 모델(예: OpenAI의 GPT와 같은)을 사용하는 애플리케이션을 구축하는 데 도움을 주는 프레임워크입니다. 주로 자연어 처리(NLP) 작업을 보다 효과적으로 수행할 수 있도록 도와주는 여러 구성 요소와 도구를 제공합니다.\n",
      "\n",
      "LangChain의 주요 기능은 다음과 같습니다:\n",
      "\n",
      "1. **체인**: 여러 단계를 연결하여 복잡한 작업을 수행할 수 있는 방법을 제공합니다. 예를 들어, 모델의 출력을 다른 API 호출에 전달하거나 저장된 데이터를 검색하는 방식으로 체인을 구성할 수 있습니다.\n",
      "\n",
      "2. **메모리**: 사용자의 입력이나 모델의 출력을 저장하고 재사용할 수 있는 메커니즘을 제공합니다. 이를 통해 보다 일관된 대화나 인터랙션을 구현할 수 있습니다.\n",
      "\n",
      "3. **로드 체인**: 외부 데이터 소스(예: 데이터베이스, 웹 API 등)에 접근하여 모델이 더 나은 응답을 생성할 수 있도록 지원합니다.\n",
      "\n",
      "4. **프롬프트 관리**: 프롬프트 템플릿을 작성하고 관리하여 일관성 있게 모델에 입력할 수 있도록 지원합니다.\n",
      "\n",
      "LangChain은 주로 대화형 애플리케이션 개발, 정보 검색, 문서 생성 등 다양한 작업에서 강력한 도구로 사용됩니다. 궁금한 점이나 더 알고 싶은 내용이 있으면 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"너는 친절한 조교야\"),\n",
    "    HumanMessage(content=\"안녕?\"),\n",
    "    AIMessage(content=\"안녕하세요! 무엇을 도와드릴까요?\"),\n",
    "    HumanMessage(content=\"Langchain이 뭐야?\")\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4f6b0e",
   "metadata": {},
   "source": [
    "### 멀티턴 대화 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6c1fd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c69e46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#세션별 대화 기록을 저장할 딕셔너리\n",
    "store = {}\n",
    "\n",
    "#세션 id에 따라 대화 기록을 가져오는 함수\n",
    "def get_session_history(session_id:str):\n",
    "    #만약 세션 id가 없으면 새로 생성해 추가\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "#모델 실행시 대화 기록을 함께 전달하는 래퍼 객체 생성\n",
    "with_messages_history = RunnableWithMessageHistory(llm, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45438da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.history.RunnableWithMessageHistory'>\n"
     ]
    }
   ],
   "source": [
    "print(type(with_messages_history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90ac0128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bound=RunnableBinding(bound=RunnableBinding(bound=RunnableLambda(_enter_history), kwargs={}, config={'run_name': 'load_history'}, config_factories=[])\n",
      "| RunnableBinding(bound=RunnableLambda(_call_runnable_sync), kwargs={}, config={'run_name': 'check_sync_or_async'}, config_factories=[]), kwargs={}, config={'run_name': 'RunnableWithMessageHistory'}, config_factories=[]) kwargs={} config={} config_factories=[] get_session_history=<function get_session_history at 0xffff7183ec20> history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)]\n"
     ]
    }
   ],
   "source": [
    "print(with_messages_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06734158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요, 홍길동님! 만나서 반가워요. 어떻게 도와드릴까요?\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\" : \"chat-001\"}} #세션 id를 설정하는 config 객체 생성\n",
    "\n",
    "response = with_messages_history.invoke(\n",
    "    [HumanMessage(content=\"안녕? 나는 홍길동이야\")],\n",
    "    config = config\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b36c8d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'session_id': 'chat-001'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6884cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "당신의 이름은 홍길동입니다. 다른 질문이나 도움이 필요하신 부분이 있나요?\n"
     ]
    }
   ],
   "source": [
    "response = with_messages_history.invoke(\n",
    "    [HumanMessage(content=\"내 이름이 뭐지?\")],\n",
    "    config = config\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64c3e34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat-001': InMemoryChatMessageHistory(messages=[HumanMessage(content='안녕? 나는 홍길동이야', additional_kwargs={}, response_metadata={}), AIMessage(content='안녕하세요, 홍길동님! 만나서 반가워요. 어떻게 도와드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 16, 'total_tokens': 38, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CT6MqwzbTaUqvkl7C3bJlK0rw6Onm', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--5ab128f3-915a-4b1d-a7d2-5f152f7f4337-0', usage_metadata={'input_tokens': 16, 'output_tokens': 22, 'total_tokens': 38, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='내 이름이 뭐지?', additional_kwargs={}, response_metadata={}), AIMessage(content='당신의 이름은 홍길동입니다. 다른 질문이나 도움이 필요하신 부분이 있나요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 52, 'total_tokens': 74, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CT6NM8fIa2egsl7cLONZauiITwC4J', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--0302da6b-ca29-4884-b2c7-4eee010443a0-0', usage_metadata={'input_tokens': 52, 'output_tokens': 22, 'total_tokens': 74, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8410e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "죄송하지만, 당신의 이름을 알 수 있는 정보가 없습니다. 당신의 이름을 알려주시면 기쁠 것 같습니다!\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\" : \"chat-002\"}} #세션 id를 설정하는 config 객체 생성\n",
    "\n",
    "response = with_messages_history.invoke(\n",
    "    [HumanMessage(content=\"내 이름이 뭐지?\")],\n",
    "    config = config\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f089eed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat-001': InMemoryChatMessageHistory(messages=[HumanMessage(content='안녕? 나는 홍길동이야', additional_kwargs={}, response_metadata={}), AIMessage(content='안녕하세요, 홍길동님! 만나서 반가워요. 어떻게 도와드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 16, 'total_tokens': 38, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CT6MqwzbTaUqvkl7C3bJlK0rw6Onm', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--5ab128f3-915a-4b1d-a7d2-5f152f7f4337-0', usage_metadata={'input_tokens': 16, 'output_tokens': 22, 'total_tokens': 38, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='내 이름이 뭐지?', additional_kwargs={}, response_metadata={}), AIMessage(content='당신의 이름은 홍길동입니다. 다른 질문이나 도움이 필요하신 부분이 있나요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 52, 'total_tokens': 74, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CT6NM8fIa2egsl7cLONZauiITwC4J', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--0302da6b-ca29-4884-b2c7-4eee010443a0-0', usage_metadata={'input_tokens': 52, 'output_tokens': 22, 'total_tokens': 74, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]),\n",
       " 'chat-002': InMemoryChatMessageHistory(messages=[HumanMessage(content='내 이름이 뭐지?', additional_kwargs={}, response_metadata={}), AIMessage(content='죄송하지만, 당신의 이름을 알 수 있는 정보가 없습니다. 당신의 이름을 알려주시면 기쁠 것 같습니다!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 13, 'total_tokens': 41, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CT6NvMwGjLWbmVptpxTpzliCfi3xy', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--62c65961-5fb4-4dac-9f32-6a2a935699b4-0', usage_metadata={'input_tokens': 13, 'output_tokens': 28, 'total_tokens': 41, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f99fc7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "우리는 처음에 당신의 이름이 홍길동이라는 걸 이야기했어요. 그 외에 다른 특정한 대화는 없었죠. 더 이야기하고 싶은 주제가 있으면 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\" : \"chat-001\"}} #세션 id를 설정하는 config 객체 생성\n",
    "\n",
    "response = with_messages_history.invoke(\n",
    "    [HumanMessage(content=\"아까 우리가 무슨 이야기 했지?\")],\n",
    "    config = config\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1145896b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat-001': InMemoryChatMessageHistory(messages=[HumanMessage(content='안녕? 나는 홍길동이야', additional_kwargs={}, response_metadata={}), AIMessage(content='안녕하세요, 홍길동님! 만나서 반가워요. 어떻게 도와드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 16, 'total_tokens': 38, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CT6MqwzbTaUqvkl7C3bJlK0rw6Onm', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--5ab128f3-915a-4b1d-a7d2-5f152f7f4337-0', usage_metadata={'input_tokens': 16, 'output_tokens': 22, 'total_tokens': 38, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='내 이름이 뭐지?', additional_kwargs={}, response_metadata={}), AIMessage(content='당신의 이름은 홍길동입니다. 다른 질문이나 도움이 필요하신 부분이 있나요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 52, 'total_tokens': 74, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CT6NM8fIa2egsl7cLONZauiITwC4J', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--0302da6b-ca29-4884-b2c7-4eee010443a0-0', usage_metadata={'input_tokens': 52, 'output_tokens': 22, 'total_tokens': 74, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='아까 우리가 무슨 이야기 했지?', additional_kwargs={}, response_metadata={}), AIMessage(content='우리는 처음에 당신의 이름이 홍길동이라는 걸 이야기했어요. 그 외에 다른 특정한 대화는 없었죠. 더 이야기하고 싶은 주제가 있으면 말씀해 주세요!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 91, 'total_tokens': 133, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CT6OQwGhgoOWF5Sn6Q3piv58THXTv', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--288fa5c6-25f4-433d-a488-4dd0725a5f4d-0', usage_metadata={'input_tokens': 91, 'output_tokens': 42, 'total_tokens': 133, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]),\n",
       " 'chat-002': InMemoryChatMessageHistory(messages=[HumanMessage(content='내 이름이 뭐지?', additional_kwargs={}, response_metadata={}), AIMessage(content='죄송하지만, 당신의 이름을 알 수 있는 정보가 없습니다. 당신의 이름을 알려주시면 기쁠 것 같습니다!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 13, 'total_tokens': 41, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CT6NvMwGjLWbmVptpxTpzliCfi3xy', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--62c65961-5fb4-4dac-9f32-6a2a935699b4-0', usage_metadata={'input_tokens': 13, 'output_tokens': 28, 'total_tokens': 41, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c95b69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
